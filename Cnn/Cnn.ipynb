{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cfcbb4",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e20c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time as timer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e7d43",
   "metadata": {},
   "source": [
    "# Loading In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7642355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird Data Shape:    (133572, 784)\n",
      "Cat Data Shape:     (123202, 784)\n",
      "Fish Data Shape:    (134150, 784)\n",
      "Horse Data Shape:   (178286, 784)\n",
      "Rabbit Data Shape:  (155288, 784)\n",
      "Penguin Data Shape:  (253791, 784)\n",
      "\n",
      "Total Data Shape:   (978289, 784)\n",
      "\n",
      "Total Num. Of Samples: 978289\n"
     ]
    }
   ],
   "source": [
    "path_bird = 'DrawData/full_numpy_bitmap_bird.npy'\n",
    "data_bird = np.load(path_bird)\n",
    "bird_shape = data_bird.shape  #(N, 784)\n",
    "print(f'Bird Data Shape:    {bird_shape}')\n",
    "\n",
    "path_cat = 'DrawData/full_numpy_bitmap_cat.npy'\n",
    "data_cat = np.load(path_cat)\n",
    "cat_shape = data_cat.shape  #(N, 784)\n",
    "print(f'Cat Data Shape:     {cat_shape}')\n",
    "\n",
    "path_fish = 'DrawData/full_numpy_bitmap_fish.npy'\n",
    "data_fish = np.load(path_fish)\n",
    "fish_shape = data_fish.shape  #(N, 784)\n",
    "print(f'Fish Data Shape:    {fish_shape}')\n",
    "\n",
    "path_horse = 'DrawData/full_numpy_bitmap_horse.npy'\n",
    "data_horse = np.load(path_horse)\n",
    "horse_shape = data_horse.shape  #(N, 784)\n",
    "print(f'Horse Data Shape:   {horse_shape}')\n",
    "\n",
    "path_rabbit = 'DrawData/full_numpy_bitmap_rabbit.npy'\n",
    "data_rabbit = np.load(path_rabbit)\n",
    "rabbit_shape = data_rabbit.shape  #(N, 784)\n",
    "print(f'Rabbit Data Shape:  {rabbit_shape}')\n",
    "\n",
    "path_penguin = 'DrawData/full_numpy_bitmap_penguin.npy'\n",
    "data_penguin = np.load(path_penguin)\n",
    "penguin_shape = data_penguin.shape  #(N, 784)\n",
    "print(f'Penguin Data Shape:  {penguin_shape}')\n",
    "\n",
    "data = np.vstack((data_bird, data_cat, data_fish, data_horse, data_rabbit, data_penguin))\n",
    "print(f'\\nTotal Data Shape:   {data.shape}')\n",
    "labels = np.array(['bird']*bird_shape[0] + ['cat']*cat_shape[0] + ['fish']*fish_shape[0] + ['horse']*horse_shape[0] + ['rabbit']*rabbit_shape[0] + ['penguin']*penguin_shape[0])\n",
    "print(f'\\nTotal Num. Of Samples: {labels.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0563e12",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4fee6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Params\n",
    "lr = 1e-4\n",
    "num_epochs = 20\n",
    "delta = 0.75\n",
    "test_size = 0.1\n",
    "val_size = 0.2\n",
    "random_state = 42\n",
    "batch_size = 8192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289cc580",
   "metadata": {},
   "source": [
    "# CNN Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f790e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoodleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DoodleCNN, self).__init__()\n",
    "        #Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,      out_channels=4,        kernel_size=(5, 5),      padding=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=4,      out_channels=16,       kernel_size=(5, 5),      padding=(2, 2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=16,     out_channels=32,       kernel_size=(5, 5),      padding=(2, 2))\n",
    "        self.conv4 = nn.Conv2d(in_channels=32,     out_channels=64,      kernel_size=(5, 5),      padding=(2, 2))\n",
    "\n",
    "        self.batchnorm1 = nn.BatchNorm(num_features=16)\n",
    "        self.batchnorm2 = nn.BatchNorm(num_features=64)\n",
    "        self.batchnorm3 = nn.BatchNorm(num_features=128)\n",
    "        \n",
    "        #MaxPooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #Fully connected layers\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "        \n",
    "        #Dropout layer\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Convolutional layers with SELU activations and MaxPooling\n",
    "        x = F.selu(self.conv1(x))\n",
    "        x = self.pool(self.batchnorm1(F.selu(self.conv2(x))))\n",
    "        x = F.selu(self.conv3(x))\n",
    "        x = self.pool(self.batchnorm2(F.selu(self.conv4(x))))\n",
    "        \n",
    "        x = x.view(-1, 64*7*7)\n",
    "        #Fully connected layers with LeakyReLU activations and Dropout\n",
    "        x = self.batchnorm3(F.leaky_relu(self.fc1(x)))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6250e16",
   "metadata": {},
   "source": [
    "# Custom Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca35c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoodleDataset(Dataset):\n",
    "\tdef __init__(self, data, labels, transform=None):\n",
    "\t\tself.data = data\n",
    "\t\tself.labels = labels\n",
    "\t\tself.transform = transform\n",
    "\t\tself.label_to_idx = {'bird': 0, 'cat': 1, 'fish': 2, 'horse': 3, 'rabbit': 4, 'penguin': 5}\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timage = self.data[idx].reshape(28, 28).astype(np.float32)/255.0  # Normalize pixel values\n",
    "\t\tlabel = self.label_to_idx[self.labels[idx]]\n",
    "\t\t\n",
    "\t\tif self.transform:\n",
    "\t\t\timage = self.transform(image)\n",
    "\t\t\n",
    "\t\timage = torch.tensor(image).unsqueeze(0)  # Add channel dimension\n",
    "\t\tlabel = torch.tensor(label).long()\n",
    "\t\t\n",
    "\t\treturn image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd3fe1",
   "metadata": {},
   "source": [
    "# Setup Training, Validation, & Testing Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95fe13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training, validation, and testing sets\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(data, labels, test_size=(test_size + val_size), random_state=random_state, stratify=labels)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=(test_size/(test_size + val_size)), random_state=random_state, stratify=y_valtest)\n",
    "\n",
    "# Setup Training, Validation, & Testing Dataloaders\n",
    "train_dataset = DoodleDataset(X_train, y_train)\n",
    "val_dataset = DoodleDataset(X_val, y_val)\n",
    "test_dataset = DoodleDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset), 'test': len(test_dataset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2f3c4",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6261e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=25):\n",
    "    #Setup model history tracking\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'test_loss': None, 'test_acc': None}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #Training\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        train_running_corrects = 0\n",
    "        for image, label in dataloaders['train']:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            outputs = model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_running_loss += loss.item()*image.size(0)\n",
    "            train_running_corrects += torch.sum(preds == label.data)\n",
    "            \n",
    "        train_epoch_loss = train_running_loss/dataset_sizes['train']\n",
    "        train_epoch_acc = train_running_corrects.double()/dataset_sizes['train']\n",
    "        scheduler.step()\n",
    "        \n",
    "        #Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_running_loss = 0.0\n",
    "            val_running_corrects = 0\n",
    "            for image, label in dataloaders['val']:\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                \n",
    "                outputs = model(image)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, label)\n",
    "                \n",
    "                val_running_loss += loss.item()*image.size(0)\n",
    "                val_running_corrects += torch.sum(preds == label.data)\n",
    "            \n",
    "            val_epoch_loss = val_running_loss/dataset_sizes['val']\n",
    "            val_epoch_acc = val_running_corrects.double()/dataset_sizes['val']\n",
    "        \n",
    "        #Printouts & appends\n",
    "        print(f'|    Epoch:  [{epoch+1:2}]/[{num_epochs:2}]    |    '\n",
    "              f'Train Loss:  [{train_epoch_loss:.4f}]    |    Train Acc:  [{train_epoch_acc:.4f}]    |    '\n",
    "              f'Val Loss:  [{val_epoch_loss:.4f}]    |    Val Acc:  [{val_epoch_acc:.4f}]    |')\n",
    "        history['train_loss'].append(train_epoch_loss)\n",
    "        history['train_acc'].append(train_epoch_acc.item())\n",
    "        history['val_loss'].append(val_epoch_loss)\n",
    "        history['val_acc'].append(val_epoch_acc.item())\n",
    "        \n",
    "    #Testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_running_loss = 0.0\n",
    "        test_running_corrects = 0\n",
    "        for image, label in dataloaders['test']:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            outputs = model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, label)\n",
    "            \n",
    "            test_running_loss += loss.item()*image.size(0)\n",
    "            test_running_corrects += torch.sum(preds == label.data)\n",
    "            \n",
    "        test_epoch_loss = test_running_loss/dataset_sizes['test']\n",
    "        test_epoch_acc = test_running_corrects.double()/dataset_sizes['test']\n",
    "    \n",
    "    #Printouts & appends\n",
    "    print(f'Test Loss: {test_epoch_loss:.4f} Acc: {test_epoch_acc:.4f}')\n",
    "    history['test_loss'] = test_epoch_loss\n",
    "    history['test_acc'] = test_epoch_acc.item()\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f3f87",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac656e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    Epoch:  [ 1]/[20]    |    Train Loss:  [1.1637]    |    Train Acc:  [0.5392]    |    Val Loss:  [0.7897]    |    Val Acc:  [0.7237]    |\n",
      "|    Epoch:  [ 2]/[20]    |    Train Loss:  [0.6894]    |    Train Acc:  [0.7633]    |    Val Loss:  [0.5536]    |    Val Acc:  [0.8118]    |\n",
      "|    Epoch:  [ 3]/[20]    |    Train Loss:  [0.5547]    |    Train Acc:  [0.8128]    |    Val Loss:  [0.4975]    |    Val Acc:  [0.8302]    |\n",
      "|    Epoch:  [ 4]/[20]    |    Train Loss:  [0.5088]    |    Train Acc:  [0.8286]    |    Val Loss:  [0.4664]    |    Val Acc:  [0.8401]    |\n",
      "|    Epoch:  [ 5]/[20]    |    Train Loss:  [0.4831]    |    Train Acc:  [0.8368]    |    Val Loss:  [0.4482]    |    Val Acc:  [0.8459]    |\n",
      "|    Epoch:  [ 6]/[20]    |    Train Loss:  [0.4674]    |    Train Acc:  [0.8416]    |    Val Loss:  [0.4369]    |    Val Acc:  [0.8495]    |\n",
      "|    Epoch:  [ 7]/[20]    |    Train Loss:  [0.4562]    |    Train Acc:  [0.8458]    |    Val Loss:  [0.4286]    |    Val Acc:  [0.8522]    |\n",
      "|    Epoch:  [ 8]/[20]    |    Train Loss:  [0.4486]    |    Train Acc:  [0.8475]    |    Val Loss:  [0.4230]    |    Val Acc:  [0.8539]    |\n",
      "|    Epoch:  [ 9]/[20]    |    Train Loss:  [0.4434]    |    Train Acc:  [0.8496]    |    Val Loss:  [0.4190]    |    Val Acc:  [0.8555]    |\n",
      "|    Epoch:  [10]/[20]    |    Train Loss:  [0.4399]    |    Train Acc:  [0.8510]    |    Val Loss:  [0.4160]    |    Val Acc:  [0.8567]    |\n",
      "|    Epoch:  [11]/[20]    |    Train Loss:  [0.4365]    |    Train Acc:  [0.8519]    |    Val Loss:  [0.4135]    |    Val Acc:  [0.8572]    |\n",
      "|    Epoch:  [12]/[20]    |    Train Loss:  [0.4351]    |    Train Acc:  [0.8524]    |    Val Loss:  [0.4119]    |    Val Acc:  [0.8580]    |\n",
      "|    Epoch:  [13]/[20]    |    Train Loss:  [0.4328]    |    Train Acc:  [0.8534]    |    Val Loss:  [0.4107]    |    Val Acc:  [0.8582]    |\n",
      "|    Epoch:  [14]/[20]    |    Train Loss:  [0.4322]    |    Train Acc:  [0.8534]    |    Val Loss:  [0.4097]    |    Val Acc:  [0.8588]    |\n",
      "|    Epoch:  [15]/[20]    |    Train Loss:  [0.4310]    |    Train Acc:  [0.8535]    |    Val Loss:  [0.4089]    |    Val Acc:  [0.8591]    |\n",
      "|    Epoch:  [16]/[20]    |    Train Loss:  [0.4300]    |    Train Acc:  [0.8538]    |    Val Loss:  [0.4084]    |    Val Acc:  [0.8595]    |\n",
      "|    Epoch:  [17]/[20]    |    Train Loss:  [0.4302]    |    Train Acc:  [0.8541]    |    Val Loss:  [0.4080]    |    Val Acc:  [0.8595]    |\n",
      "|    Epoch:  [18]/[20]    |    Train Loss:  [0.4297]    |    Train Acc:  [0.8542]    |    Val Loss:  [0.4077]    |    Val Acc:  [0.8595]    |\n",
      "|    Epoch:  [19]/[20]    |    Train Loss:  [0.4291]    |    Train Acc:  [0.8544]    |    Val Loss:  [0.4075]    |    Val Acc:  [0.8596]    |\n",
      "|    Epoch:  [20]/[20]    |    Train Loss:  [0.4290]    |    Train Acc:  [0.8543]    |    Val Loss:  [0.4073]    |    Val Acc:  [0.8597]    |\n",
      "Test Loss: 0.4061 Acc: 0.8607\n"
     ]
    }
   ],
   "source": [
    "#Training Setup\n",
    "model = DoodleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=delta)\n",
    "trained_model, history = train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save Model Weights\n",
    "# torch.save(trained_model.state_dict(), 'doodle_cnn_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5489aa",
   "metadata": {},
   "source": [
    "# Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1766aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot Loss and Accuracy Curves\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# ax1.plot(history['train_loss'], label='Train Loss')\n",
    "# ax1.plot(history['val_loss'], label='Val Loss')\n",
    "# ax1.axhline(history['test_loss'], color='r', linestyle='--', label='Test Loss')\n",
    "# ax1.set_title('Loss Curves')\n",
    "# ax1.set_xlabel('Epoch')\n",
    "# ax1.set_ylabel('Loss')\n",
    "# ax1.legend()\n",
    "\n",
    "# ax2.plot(history['train_acc'], label='Train Acc')\n",
    "# ax2.plot(history['val_acc'], label='Val Acc')\n",
    "# ax2.axhline(history['test_acc'], color='r', linestyle='--', label='Test Acc')\n",
    "# ax2.set_title('Accuracy Curves')\n",
    "# ax2.set_xlabel('Epoch')\n",
    "# ax2.set_ylabel('Accuracy')\n",
    "# ax2.legend()\n",
    "\n",
    "# fig.savefig('training_history.png', dpi=96, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5ce7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Confusion Matrix\n",
    "# def plot_confusion_matrix(model, dataloader, classes):\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#     model.eval()\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in dataloader:\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "#     cm = confusion_matrix(all_labels, all_preds)\n",
    "#     cm_percent = np.round(100*cm.astype('float')/cm.sum(axis=1)[:, np.newaxis], 1)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.imshow(cm_percent, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "#     for i in range(len(classes)):\n",
    "#         for j in range(len(classes)):\n",
    "#             plt.text(j, i, f'{cm_percent[i, j]}%', horizontalalignment=\"center\", color=\"white\" if cm_percent[i, j] > cm_percent.max()/2. else \"black\")\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('True')\n",
    "#     plt.title('Confusion Matrix')\n",
    "#     plt.savefig('confusion_matrix.png', dpi=96, bbox_inches='tight')\n",
    "\n",
    "# plot_confusion_matrix(trained_model, dataloaders['test'], classes=['bird', 'cat', 'fish', 'horse', 'rabbit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "046b474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show some examples with logits\n",
    "# def show_examples_with_logits(model, dataloader, classes, num_examples=4):\n",
    "#     fig, axes = plt.subplots(2, num_examples, figsize=(5*num_examples, 10))\n",
    "    \n",
    "#     Label_fs = 25\n",
    "#     Ltitle_fs = 30\n",
    "#     Llabels_fs = 14\n",
    "#     lylabel_fs = 15\n",
    "    \n",
    "#     model.eval()\n",
    "#     axes[1, 0].set_ylabel('Logit Value', fontsize=lylabel_fs)\n",
    "#     examples_shown = 0\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in dataloader:\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "#             for i in range(images.size(0)):\n",
    "#                 if examples_shown >= num_examples:\n",
    "#                     break\n",
    "#                 img = images[i].cpu().squeeze().numpy()\n",
    "#                 true_label = classes[labels[i].item()]\n",
    "#                 pred_label = classes[preds[i].item()]\n",
    "#                 logits = np.round(outputs[i].cpu().numpy(),2)\n",
    "                \n",
    "#                 #Add example to top row\n",
    "#                 axes[0, examples_shown].imshow(img, cmap='gray')\n",
    "#                 axes[0, examples_shown].set_title(f'True: {true_label}\\nPred: {pred_label}', fontsize=Label_fs)\n",
    "#                 axes[0, examples_shown].axis('off')\n",
    "                \n",
    "#                 #Add Bar chart to bottom row\n",
    "#                 axes[1, examples_shown].bar(classes, logits, color='blue')\n",
    "#                 axes[1, examples_shown].set_title('Logits', fontsize=Ltitle_fs)\n",
    "#                 axes[1, examples_shown].set_ylim([min(logits)-1, max(logits)+1])\n",
    "#                 axes[1, examples_shown].tick_params(axis='x', labelsize=Llabels_fs)\n",
    "#                 examples_shown += 1\n",
    "#             if examples_shown >= num_examples:\n",
    "#                 break\n",
    "#     fig.savefig('examples_with_logits.png', dpi=96, bbox_inches='tight')\n",
    "\n",
    "# show_examples_with_logits(trained_model, dataloaders['test'], classes=['bird', 'cat', 'fish', 'horse', 'rabbit'], num_examples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f61639",
   "metadata": {},
   "source": [
    "# Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "932a8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow<2.16 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/home/theel/.pyenv/versions/3.12.11/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow<2.16\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "!{sys.executable} -m pip install 'tensorflow[and-cuda]<2.16' 'tensorflowjs[wizard]<4.20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af0d6c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 22:32:45.010304: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-15 22:32:45.017120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763263965.024320 1009943 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763263965.026485 1009943 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1763263965.034495 1009943 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763263965.034501 1009943 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763263965.034502 1009943 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763263965.034503 1009943 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-15 22:32:45.037732: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "460fdc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Params\n",
    "lr = 1e-4\n",
    "num_epochs = 20\n",
    "delta = 0.75\n",
    "test_size = 0.2\n",
    "validation_split = 0.1\n",
    "batch_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5515906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Found GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Success! TensorFlow will use the GPU.\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f\"Found GPUs: {gpus}\")\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        # Enable memory growth to avoid allocating all GPU memory at once\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"Success! TensorFlow will use the GPU.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"FAILURE: No GPU was found by TensorFlow.\")\n",
    "    print(\"Training will be on the CPU (which will be very slow).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88196249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 15 22:32:46 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0 Off |                  Off |\n",
      "|  0%   36C    P8             16W /  450W |     524MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1639      G   /usr/lib/xorg/Xorg                      338MiB |\n",
      "|    0   N/A  N/A            2806      G   cinnamon                                 31MiB |\n",
      "|    0   N/A  N/A            4010      G   ...rack-uuid=3190708988185955192         39MiB |\n",
      "|    0   N/A  N/A            5539      G   /usr/share/code/code                     56MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a504180a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763263967.949023 1009943 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21629 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 4)         104       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 16)        1616      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 28, 28, 16)        64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 32)        12832     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 14, 14, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               401536    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 476830 (1.82 MB)\n",
      "Trainable params: 476414 (1.82 MB)\n",
      "Non-trainable params: 416 (1.62 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763263971.069609 1010429 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763263972.154263 1010429 service.cc:152] XLA service 0x7786ca9c2490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763263972.154278 1010429 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-11-15 22:32:52.157406: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1763263972.222253 1010429 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 11s 41ms/step - loss: 0.6793 - accuracy: 0.7753 - val_loss: 0.9111 - val_accuracy: 0.6668\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4037 - accuracy: 0.8693 - val_loss: 0.3945 - val_accuracy: 0.8745\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.3493 - accuracy: 0.8863 - val_loss: 0.3150 - val_accuracy: 0.8969\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.3186 - accuracy: 0.8957 - val_loss: 0.3119 - val_accuracy: 0.8963\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2976 - accuracy: 0.9023 - val_loss: 0.2861 - val_accuracy: 0.9050\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2833 - accuracy: 0.9068 - val_loss: 0.2758 - val_accuracy: 0.9072\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2711 - accuracy: 0.9109 - val_loss: 0.2650 - val_accuracy: 0.9118\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2614 - accuracy: 0.9139 - val_loss: 0.2612 - val_accuracy: 0.9127\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2539 - accuracy: 0.9163 - val_loss: 0.2557 - val_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2474 - accuracy: 0.9183 - val_loss: 0.2504 - val_accuracy: 0.9156\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2422 - accuracy: 0.9201 - val_loss: 0.2465 - val_accuracy: 0.9170\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2376 - accuracy: 0.9214 - val_loss: 0.2450 - val_accuracy: 0.9180\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2343 - accuracy: 0.9229 - val_loss: 0.2441 - val_accuracy: 0.9189\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2309 - accuracy: 0.9237 - val_loss: 0.2403 - val_accuracy: 0.9190\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2291 - accuracy: 0.9242 - val_loss: 0.2392 - val_accuracy: 0.9196\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2272 - accuracy: 0.9251 - val_loss: 0.2381 - val_accuracy: 0.9199\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2254 - accuracy: 0.9254 - val_loss: 0.2374 - val_accuracy: 0.9203\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2254 - accuracy: 0.9255 - val_loss: 0.2371 - val_accuracy: 0.9202\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2245 - accuracy: 0.9255 - val_loss: 0.2370 - val_accuracy: 0.9202\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.2241 - accuracy: 0.9258 - val_loss: 0.2370 - val_accuracy: 0.9202\n",
      "Model saved as my_mnist_cnn_v4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theel/.pyenv/versions/3.12.11/lib/python3.12/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#Split data into training and testing sets\n",
    "classes = np.unique(labels)\n",
    "num_classes = len(classes)\n",
    "label_map = {label: idx for idx, label in enumerate(classes)}\n",
    "num_labels = np.array([label_map[label] for label in labels])\n",
    "data_res = data.reshape(-1, 28, 28, 1).astype(np.float32)/255.0  # Reshape and normalize for TensorFlow\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_res, num_labels, test_size=test_size, stratify=labels)\n",
    "\n",
    "num_train_samples = len(X_train) * (1.0 - validation_split)\n",
    "steps_per_epoch = np.ceil(num_train_samples / batch_size)\n",
    "decay_steps = int(steps_per_epoch * num_epochs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=lr,\n",
    "    decay_steps=decay_steps,\n",
    "    alpha=0.0  # The minimum learning rate as a fraction of the initial_lr. 0.0 anneals to zero.\n",
    ")\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "#Define TensorFlow CNN Model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(28, 28, 1)),\n",
    "\tlayers.Conv2D(4, (5, 5), padding='same', activation='selu'),\n",
    "\tlayers.Conv2D(16, (5, 5), padding='same', activation='selu'),\n",
    "\tlayers.BatchNormalization(),\n",
    "\tlayers.MaxPooling2D((2, 2)),\n",
    "\tlayers.Conv2D(32, (5, 5), padding='same', activation='selu'),\n",
    "\tlayers.Conv2D(64, (5, 5), padding='same', activation='selu'),\n",
    "\tlayers.BatchNormalization(),\n",
    "\tlayers.MaxPooling2D((2, 2)),\n",
    "\tlayers.Flatten(),\n",
    "\tlayers.Dense(128, activation='leaky_relu'),\n",
    "\tlayers.BatchNormalization(),\n",
    "\tlayers.Dense(64, activation='leaky_relu'),\n",
    "\tlayers.Dropout(0.25),\n",
    "\tlayers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "#Display Model Summary\n",
    "model.summary()\n",
    "\n",
    "#Compile and Train the Model\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=validation_split)\n",
    "\n",
    "#Save the Model\n",
    "model.save(\"my_mnist_cnn_v4.h5\")\n",
    "print(\"Model saved as my_mnist_cnn_v4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e9de8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_cnn_v4_savedmodel_legacy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_cnn_v4_savedmodel_legacy/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'my_mnist_cnn_v4_savedmodel_legacy'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  131454686845200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686845776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686845392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686844432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686844240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686845584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686845008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686843472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686846544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686847120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686844816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686847504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686845968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686846736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686846160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686846352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686848656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686849232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686848080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686844624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686848272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686848464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686850192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686850768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686849808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131454686850960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model saved as my_mnist_cnn_v4_savedmodel_legacy\n",
      "Model saved as my_mnist_cnn_v4_legacy.h5\n",
      "Model saved as my_mnist_cnn_v4_legacy.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theel/.pyenv/versions/3.12.11/lib/python3.12/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tensorflowjs_converter --input_format=keras Cnn/my_mnist_cnn_v4_legacy.h5 ./tfjs_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m model.save(\u001b[33m\"\u001b[39m\u001b[33mmy_mnist_cnn_v4_legacy.keras\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel saved as my_mnist_cnn_v4_legacy.keras\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtensorflowjs_converter --input_format=keras Cnn/my_mnist_cnn_v4_legacy.h5 ./tfjs_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.11/lib/python3.12/subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    545\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    546\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    550\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.11/lib/python3.12/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.11/lib/python3.12/subprocess.py:1955\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1953\u001b[39m     err_msg = os.strerror(errno_num)\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1955\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1956\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1957\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'tensorflowjs_converter --input_format=keras Cnn/my_mnist_cnn_v4_legacy.h5 ./tfjs_model'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "model.export(\"my_mnist_cnn_v4_savedmodel_legacy\")\n",
    "print(\"Model saved as my_mnist_cnn_v4_savedmodel_legacy\")\n",
    "model.save(\"my_mnist_cnn_v4_legacy.h5\")\n",
    "print(\"Model saved as my_mnist_cnn_v4_legacy.h5\")\n",
    "model.save(\"my_mnist_cnn_v4_legacy.keras\")\n",
    "print(\"Model saved as my_mnist_cnn_v4_legacy.keras\")\n",
    "\n",
    "subprocess.run(\"tensorflowjs_converter --input_format=keras Cnn/my_mnist_cnn_v4_legacy.h5 ./tfjs_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09006d36",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be034e8",
   "metadata": {},
   "source": [
    "* Add Timing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.11",
   "language": "python",
   "name": "pyenv_3.12.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
